## *时间线: 现在2022.08.14*    
### 整个流程    
> #### 1. 
> > #### 过滤没有 关键词 | 摘要 | 标题 | 出版年月 的数据, 然后再将数据按照出版年月排序, 并且, 对于同一出版年月的数据, 按照DOI进行二次排序.
> > #### 然后, 缺失数据处理，对缺失月份的期刊数据进行填充，填充方式为月份向前平均填充。将每个期刊的数据, 进行按月平均, 如: SCIENTOMETRICS期刊缺失2018-01 2018-02的数据, 则利用2018-03的数据, 平均到这三个月。
> #### 2. 
> > #### 使用python spacy包 进行 去停用词词性还原 处理; 使用python spacy包对摘要进行多词分词（2个词以内，包括2个词）；
> > #### 利用python spacy的词向量模型（en_core_web_lg）对分词结果与对应的关键词进行相似度计算，获取相似度最高的3个词对对应的关键词进行补充（以处理摘要中不含关键词的情形，按摘要对关键词进行修正）；再通过检索技术爬取（公认的，他人定义的）科学常用词，进行去科学常用词处理。
> > #### 对 论文标题和摘要 进行 去停用词 去前100高频词（对现有的摘要和标题进行词统计，由于我们获取的科学常用词不完全的一个修正） 词性还原 保留关键词(将关键词使用 _ 连接，变成一个词) 处理, 并使用 句子（每个列表都是句子）(被word2vec用于训练以建立词向量模型 ) & 摘要(每个列表都是摘要，用于node2vec & jaccard) 两种模式对 摘要 进行存储。
> #### 3.
> > #### 使用分段线性法对于以下折线图进行分段 -- x为出版年月, y为该出版年月的关键词种类数 -- , 确定时间分区
> > #### 分段线性法-自顶向下TD算法：https://www.cnblogs.com/by1990/archive/2011/01/15/1936296.html
> > #### 我基于此提了一点优化（为了防止关键词个数的时间序列波动过大造成的误分）：限制每个时间分区最小必须跨越5个月份。
> #### 4.
> > #### 将 关键词 & 摘要(两种模式) 按照时间分区进行收集
> #### 5.
> > #### 对按时间分区收集的 关键词 配合摘要 作 图网络 & 模型
> > > - ##### word2vec: 利用每个时间分区的 摘要(句子集合) 做为训练集, 分别训练出每个时间分区的word2vec模型, 模型参数: 剔除词频<=3, 二次采样阈值=1e-4（对高频词进行预处理）,  采样窗口=3, 负采样噪声k=5, 模型类型: skip gram跳字模型, 词向量维度=100, 参考链接: https://github.com/ShusenTang/Dive-into-DL-PyTorch/blob/master/docs/chapter10_natural-language-processing/10.3_word2vec-pytorch.md. 利用该word2vec模型, 计算时间分区内的关键词相似度, 将所有 相似度 > 阈值0.3（参考陈翔论文-以往经验） 的两个关键词构建边, 构建 关键词图网络。（后面利用该图网络进行社区划分，时空错位）。同时, 利用相邻时间分区的 摘要(句子集合) 训练出融合年代的word2vec模型和关键词图网络；利用所有 摘要(句子集合) 训练出一个全时区word2vec模型 和 全时区关键词图网络。（跨越时间社区划分，跑不动，加载不了）
> > > - ##### node2vec: 利用每个时间分区的每个 摘要（一个摘要存成一个列表）, 设置共现窗口为3, 将所有摘要的单词作为点, 根据是否在共现窗口出现构造边, 制作出 摘要图, 然后从摘要图中, 制作出仅含以关键词为节点的子图. 子图的边构造如下: 如果任意两个关键词在原图中是直接连接的, 则子图中这两个关键词也是直接连接的, 如果任意两个关键词在原图中不是直连的, 则判断这两个关键词的最短路中, 是否包含其他该子图的点, 如果包含, 则不处理, 如果不包含，则对这两个关键词构建新边. 然后将每个时间分区内的所有子图进行合并, 形成各自时间分区的 关键词图网络. 然后将各自的 关键词图网络 做训练集, 分别训练出各自时间分区的node2vec模型--node2vec模型是利用多次随机游走重新制作新句子集, 然后根据新句子集进行word2vec训练. Model = Node2Vec(matrix_, embedding_dim=128(词向量的维数), walk_length=20, contex_size=3, walks_per_node=50, num_negative_samples=15(负采样，15个词)，sparse=True, q=0.25, p=1), 同时, 利用相邻时间分区的 关键词图网络 训练出融合年代的node2vec模型和关键词图网络, 利用所有 关键词图网络 训练出一个全时区node2vec模型 和全时区关键词图网络, 参考链接: https://www.bilibili.com/video/BV1BS4y1E7tf
> > > - ##### jaccard: 利用每个时间分区的每个 摘要（一个摘要存成一个列表）, 设置共现窗口为3, 将所有摘要的单词作为点, 根据是否在共现窗口出现构造边, 制作出 摘要图, 然后从摘要图中, 制作出仅含以关键词为节点的子图. 子图的边构造如下: 如果任意两个关键词在原图中是直接连接的, 则子图中这两个关键词也是直接连接的, 如果任意两个关键词在原图中不是直连的, 则判断这两个关键词的最短路中, 是否包含其他该子图的点, 如果包含, 则不处理, 如果不包含，则对这两个关键词构建新边. 然后将每个时间分区内的所有子图进行合并, 形成各自时间分区的 关键词图网络. 并且, jaccard不制作（相似度）模型.
> #### 6.
> > #### 对每个时间分区的 关键词图网络 进行二点连通-louvain划分, 得到每个时间分区的社区子图, 使用度中心性(代表社交关联强度)>0.1或z-得分(代表社交相似强度)>2.5筛选出主节点, 作为该子社区的关键词(社区代表词), 定义一套新的相邻年代的演变方式: 对于相邻年代-(年代1, 年代2), 使用融合年代(两者图交集)来观察演变, 融合年代解释: 融合年代是两个图的并集, 它代表着新老社区的混合, 同时也隐含着新老社区的关联, 通过观察老年代和融合年代的社区划分, 可以知道老年代在演变过程中, 逐渐和那些词有了新的交集, 再通过观察新社区的社区划分, 了解到新年代的词又如何进行关联, 过程: 老年代社区划分, 融合年代社区划分, 新年代社区划分, 老年代和新年代进行社区代表词筛选, 融合年代不进行筛选, 计算老年代每个社区与融合年代的所有社区的交集点数量, 选取 最大数量的融合年代社区 作为老年代与融合年代的演变, 对于新年代也进行类似操作, 选取 最大数据的融合年代社区 作为融合年代与新年代的演变. 此时, 老年代的社区和新年代的社区, 通过融合年代进行关联
> #### 7.
> > #### 利用 融合年代模型, 计算相邻时间分区的 社区代表词 之间的相关性, 其中, word2vec & node2vec 是利用模型, 将词转化成向量, 计算两个向量之间的余弦相似度, 其实只要新老年代的社区通过一个融合年代进行关联, 就说明他们的词是相关的, 此时只需要计算: 对于新年代社区的词, 老年代社区哪个词贡献最大即可, jaccard是利用 融合年代图网络, 计算两个词之间的jaccard值: 如果这两个词在图网络中相邻, 则jaccard值 = len(词1邻居∩词2邻居) / len(词1邻居∪词2邻居), 如果这两个词在图网络中最短路距离为2, 则jaccard值= 0.5 * len(词1邻居∩词2邻居) / len(词1邻居∪词2邻居), 如果这两个词在图网络中最短路距离>2, 则jaccard值= 0, 我们依旧选取 值最大 作为新老词的关联
> #### 8. 
> > #### 利用6的演变, 制作时间社区演绎图: 该图只包含有边相连的社区点, 主要用来发现 社区的演绎
> #### 9. 
> > #### 利用6的演变, 制作时间社区全状态演绎图: 该图包含所有的 社区 , 同时根据颜色, 显示出社区演绎的六种状态 -- 新生: 红色   消亡: 蓝色   继承: 绿色   分裂: 紫色   融合: 黄色   孤立: 棕色   其他: 灰色   融合中介社区: 粉色
> #### 10. 
> > #### 统计了每个时区的关键词词频情况, 可以直观感受关键词的演绎, 主要利用该图评价我们算法的演绎情况
### 社区演绎
> > #### 新生: T时间窗口未出现, T+1时间窗口出现, 与T时间窗内主题无关联, 且与T+2时间窗内主题有关联的主题
> > #### 消亡: T时间窗出现, T+1时间窗没有出现, 且与T+1时间窗内主题无关联的主题
> > #### 继承: T时间窗内主题i和T+1时间窗内主题j, 两者间有且只有一条关联, 则二者为继承关系
> > #### 分裂: T时间窗内主题i和T+1时间窗内多个主题存在较强关联, 则认为主题i发生分裂
> > #### 融合: T+1时间窗内主题j与T时间窗内多个主题存在较强关联, 则认为主题j是融合发展的主题
> > #### 孤立: T+1时间窗内主题j与T时间窗内所有主题以及T+2时间窗内所有主题均无关联, 只孤立的出现在当前时间窗
